{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lower(text):\n",
    "    result = \" \".join([word.lower() for word in text.split()])\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_punc(text):\n",
    "    remove = str.maketrans('', '', (string.punctuation + 'Â£'))\n",
    "    return text.translate(remove)\n",
    "\n",
    "\n",
    "def remove_nums(text):\n",
    "    remove = str.maketrans('', '', string.digits)\n",
    "    return text.translate(remove)\n",
    "\n",
    "\n",
    "def stemmer_nltk(text):\n",
    "    stemmed = \" \".join(stemmer.stem(word) for word in text.split())\n",
    "    return stemmed\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = \" \".join([word for word in text.split() if word not in stoplist])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_dataset(df):\n",
    "    train, test, ytrain, ytest = train_test_split(df['item_name'], df['category'], test_size=0.2, random_state=88)\n",
    "\n",
    "    return train, test, ytrain, ytest\n",
    "\n",
    "\n",
    "def create_labels(train_labels, test_labels, labels):\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    encoder.fit(labels)\n",
    "\n",
    "    y_train = encoder.transform(train_labels)\n",
    "    y_val = encoder.transform(test_labels)\n",
    "\n",
    "    return y_train, y_val\n",
    "\n",
    "\n",
    "def get_vectors(train_data, val_data):\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    train_data = vectorizer.fit_transform(train_data)\n",
    "    val_data = vectorizer.transform(val_data)\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def get_lr_model(x, y, iter=100):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=iter, n_jobs=8).fit(x, y)\n",
    "\n",
    "    return lr\n",
    "\n",
    "def get_nb_model(x,y):\n",
    "    nb = MultinomialNB().fit(x, y)\n",
    "\n",
    "    return nb\n",
    "\n",
    "def get_svm_model(x,y):\n",
    "    svm = SVC().fit(x,y)\n",
    "\n",
    "    return svm\n",
    "\n",
    "\n",
    "def get_acc(m, x, y):\n",
    "    predictions = m.predict(x)\n",
    "\n",
    "    acc = np.mean(predictions == y)*100\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amazon_data = pd.read_csv(\"amazon-pqa-reduced-100.csv\",index_col=0)\n",
    "amazon_labels = amazon_data.category.unique()\n",
    "shopmania_data = pd.read_csv(\"shopmania-reduced-100.csv\", index_col=0)\n",
    "shopmania_labels = shopmania_data.category.unique()\n",
    "custom_data = pd.read_csv(\"products_list_final.csv\", index_col=0)\n",
    "custom_labels = custom_data.category.unique()\n",
    "custom_data.columns = [\"store_name\", \"item_name\", \"category\"]\n",
    "\n",
    "datasets = {'amazon': [amazon_data.copy(), amazon_labels], 'shopmania': [shopmania_data.copy(), shopmania_labels], 'custom': [custom_data.copy(), custom_labels]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>P10 Projector Eight Core S912 HD DLP Mini Inte...</td>\n",
       "      <td>video_projectors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>Sony DCR-DVD910 4MP DVD Handycam Camcorder wit...</td>\n",
       "      <td>camcorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>Weathertech W298-W302-W304 All Weather Floor Mats</td>\n",
       "      <td>floor_mats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              item_name          category\n",
       "9720  P10 Projector Eight Core S912 HD DLP Mini Inte...  video_projectors\n",
       "1249  Sony DCR-DVD910 4MP DVD Handycam Camcorder wit...        camcorders\n",
       "3191  Weathertech W298-W302-W304 All Weather Floor Mats        floor_mats"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>jane iredale liquid minerals a foundation 30ml...</td>\n",
       "      <td>Women Cosmetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>morphic 3603 m36 series mens watch</td>\n",
       "      <td>Watches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyle hd smart projector with built in dual cor...</td>\n",
       "      <td>Projectors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              item_name         category\n",
       "6452  jane iredale liquid minerals a foundation 30ml...  Women Cosmetics\n",
       "1886                 morphic 3603 m36 series mens watch          Watches\n",
       "4279  pyle hd smart projector with built in dual cor...       Projectors"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopmania_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_name</th>\n",
       "      <th>item_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>TESCO</td>\n",
       "      <td>Tesco Medium Free Range Eggs 12 Pack</td>\n",
       "      <td>groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>TESCO</td>\n",
       "      <td>F/RANGE EGGS</td>\n",
       "      <td>groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>TESCO</td>\n",
       "      <td>SMIRNOFF ICE</td>\n",
       "      <td>alcohol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store_name                             item_name   category\n",
       "529      TESCO  Tesco Medium Free Range Eggs 12 Pack  groceries\n",
       "324      TESCO                          F/RANGE EGGS  groceries\n",
       "142      TESCO                          SMIRNOFF ICE    alcohol"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing, experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final(df, name, labels):\n",
    "    df['item_name'] = df['item_name'].astype(str)\n",
    "    df['item_name'] = df['item_name'].apply(lower)\n",
    "    df['item_name'] = df['item_name'].apply(remove_punc)\n",
    "    df['item_name'] = df['item_name'].apply(remove_nums)\n",
    "    df['item_name'] = df['item_name'].apply(remove_stopwords)\n",
    "    df['item_name'] = df['item_name'].apply(stemmer_nltk)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = split_dataset(df)\n",
    "\n",
    "    Y_train, Y_test = create_labels(Y_train, Y_test, labels)\n",
    "    X_train, X_test = get_vectors(X_train, X_test)\n",
    "    lr_model = get_lr_model(X_train, Y_train)\n",
    "\n",
    "    lr_acc = get_acc(lr_model, X_test, Y_test)\n",
    "    print(f\"Logistic regression accuracy on {name} dataset: {lr_acc:.2f}%\")\n",
    "\n",
    "    return lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy on amazon dataset: 84.85%\n",
      "Time taken to process amazon dataset: 0.04m\n",
      "Logistic regression accuracy on shopmania dataset: 78.99%\n",
      "Time taken to process shopmania dataset: 0.03m\n",
      "Logistic regression accuracy on custom dataset: 79.55%\n",
      "Time taken to process custom dataset: 0.00m\n"
     ]
    }
   ],
   "source": [
    "for key, dataset in datasets.items():\n",
    "    name = key\n",
    "\n",
    "    start = process_time()\n",
    "\n",
    "    lr_acc = run_final(dataset[0], name, dataset[1])\n",
    "\n",
    "    stop = process_time()\n",
    "\n",
    "    print(f\"Time taken to process {name} dataset: {(stop-start)/60:.2f}m\")\n",
    "    datasets[key].append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 84.85000000000001]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "5 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\internals\\construction.py:982\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=980'>981</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=981'>982</a>\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=982'>983</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=983'>984</a>\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\internals\\construction.py:1030\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1027'>1028</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1028'>1029</a>\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1029'>1030</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1030'>1031</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1031'>1032</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1032'>1033</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1033'>1034</a>\u001b[0m \u001b[39melif\u001b[39;00m is_mi_list:\n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1034'>1035</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=1035'>1036</a>\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 5 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\University\\FYP\\final\\preprocessing copy.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University/FYP/final/preprocessing%20copy.ipynb#ch0000011?line=3'>4</a>\u001b[0m combined \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m([key] \u001b[39m+\u001b[39m dataset[\u001b[39m2\u001b[39m:])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University/FYP/final/preprocessing%20copy.ipynb#ch0000011?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(combined)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University/FYP/final/preprocessing%20copy.ipynb#ch0000011?line=5'>6</a>\u001b[0m new_line \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame([combined], columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mremove numbers\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnums + stemmed\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnums + remove stopwords\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnums + stemmed + stopwords\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University/FYP/final/preprocessing%20copy.ipynb#ch0000011?line=7'>8</a>\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([results, new_line])\n",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=715'>716</a>\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=716'>717</a>\u001b[0m         \u001b[39m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=717'>718</a>\u001b[0m         \u001b[39m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=718'>719</a>\u001b[0m         \u001b[39m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=719'>720</a>\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=720'>721</a>\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=721'>722</a>\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=722'>723</a>\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=723'>724</a>\u001b[0m         data,\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=724'>725</a>\u001b[0m         columns,\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=725'>726</a>\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=726'>727</a>\u001b[0m         dtype,\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=727'>728</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=728'>729</a>\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=729'>730</a>\u001b[0m         arrays,\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=730'>731</a>\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=733'>734</a>\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=734'>735</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/frame.py?line=735'>736</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\internals\\construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=515'>516</a>\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=516'>517</a>\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=518'>519</a>\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=519'>520</a>\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=521'>522</a>\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\internals\\construction.py:883\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=879'>880</a>\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=880'>881</a>\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=882'>883</a>\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=883'>884</a>\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\pandas\\core\\internals\\construction.py:985\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=981'>982</a>\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=982'>983</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=983'>984</a>\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=984'>985</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=986'>987</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[0;32m    <a href='file:///c%3A/Users/grace/.conda/envs/FYP/lib/site-packages/pandas/core/internals/construction.py?line=987'>988</a>\u001b[0m     contents \u001b[39m=\u001b[39m _convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 5 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({}, columns=[\"name\", \"remove numbers\", \"nums + stemmed\", \"nums + remove stopwords\", \"nums + stemmed + stopwords\"])\n",
    "\n",
    "for key, dataset in datasets.items():\n",
    "    combined = list([key] + dataset[2:])\n",
    "    print(combined)\n",
    "    new_line = pd.DataFrame([combined], columns=[\"name\", \"remove numbers\", \"nums + stemmed\", \"nums + remove stopwords\", \"nums + stemmed + stopwords\"])\n",
    "\n",
    "    results = pd.concat([results, new_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>remove numbers</th>\n",
       "      <th>nums + stemmed</th>\n",
       "      <th>nums + remove stopwords</th>\n",
       "      <th>nums + stemmed + stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>84.4</td>\n",
       "      <td>85.05</td>\n",
       "      <td>84.85</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shopmania</td>\n",
       "      <td>78.67975</td>\n",
       "      <td>78.813559</td>\n",
       "      <td>78.858162</td>\n",
       "      <td>78.902765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom</td>\n",
       "      <td>81.060606</td>\n",
       "      <td>80.30303</td>\n",
       "      <td>79.545455</td>\n",
       "      <td>79.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name remove numbers nums + stemmed nums + remove stopwords  \\\n",
       "0     amazon           84.4          85.05                   84.85   \n",
       "0  shopmania       78.67975      78.813559               78.858162   \n",
       "0     custom      81.060606       80.30303               79.545455   \n",
       "\n",
       "  nums + stemmed + stopwords  \n",
       "0                      84.75  \n",
       "0                  78.902765  \n",
       "0                  79.545455  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data():\n",
    "    datasets['amazon'][0] = amazon_data.copy()\n",
    "    datasets['shopmania'][0] = shopmania_data.copy()\n",
    "    datasets['custom'][0] = custom_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_data()\n",
    "\n",
    "for key, dataset in datasets.items():\n",
    "\n",
    "    df = dataset[0]\n",
    "\n",
    "    df['item_name'] = df['item_name'].astype(str)\n",
    "    df['item_name'] = df['item_name'].apply(lower)\n",
    "    df['item_name'] = df['item_name'].apply(remove_punc)\n",
    "    df['item_name'] = df['item_name'].apply(remove_nums)\n",
    "    df['item_name'] = df['item_name'].apply(stemmer_nltk)\n",
    "\n",
    "    csv_name = '../cleaned/' + key + '-cleaned.csv'\n",
    "\n",
    "    df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['custom'][0]\n",
    "\n",
    "df['item_name'] = df['item_name'].astype(str)\n",
    "df['item_name'] = df['item_name'].apply(lower)\n",
    "df['item_name'] = df['item_name'].apply(remove_punc)\n",
    "df['item_name'] = df['item_name'].apply(remove_nums)\n",
    "#df['item_name'] = df['item_name'].apply(remove_stopwords)\n",
    "#df['item_name'] = df['item_name'].apply(stemmer_nltk)\n",
    "\n",
    "csv_name = '../cleaned/custom-cleaned.csv'\n",
    "\n",
    "df.to_csv(csv_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f206b6c75a13f92bc97dfa1e930151b21df17184be9d9c72a2ae387f01f205b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('FYP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
